### ElasticSearch_基础

#### 全文搜索

##### 数据结构

+ 结构化数据：也称为行数据，是由二维表结构表达逻辑关系，严格的遵循数据格式和长度规范，主要通过关系型数据库存储和管理！

+ 非结构化数据：指数据结构不规则 或者 不完整，没有预定义的数据类型，不方便使用二维逻辑表来表现的数据！

  例如：办公文档、文本、图片、XML、HTML、音视频等等！

##### 非结构化数据检索

1. 顺序扫描法（Serial Scanning）

   从头到尾，顺序扫描。适用于数据量较小的场景！

   例如：操作系统中搜索文件时，就是使用 顺序扫描法！

2. 全文搜索（Full-text Search）

   将非结构化数据中的一部分提取出来，重新对其组织，形成具有一定结构的数据，对这部分数据检索，从而达到较高的效率！

   ```
   从 非结构化数据 中提取标志性数据作为索引，进而将非结构化数据转换为结构化数据，通过对索引检索，能提高效率！

   应用场景：适合于大文件，数据量大的场景！
   ```

##### 概念

+ 全文搜索：在文件的所有文本 中 检索 与搜索项 相匹配的记录 这个过程就是全文搜索！

##### 实现原理 

1. 建立文本库：存放需要检索的数据源！

2. 建立索引：为数据源中的文本，按照指定方式 建立索引！

   例如：汉字字典中为所有的文字 建立一套 偏旁索引，或者 建立一套 拼音索引！

3. 执行搜索：由用户发起请求，搜索引擎 将 解析并处理 用户请求，将结果返回！

4. 过滤结果：在最终响应搜索结果之前，先将数据过滤，例如：数据分页、按匹配度排序等等！

##### 基于 Java 的开源实现

1. Lucene

   Lucene 是基于 Java 的最先进，功能最强大的全文搜索引擎！

   lucene 开发非常复杂，即便是写一些简单的功能，也要写大量的代码，并且需要深入理解其原理！

2. ElasticSearch

   EalsticSearch 是分布式的 **文档存储引擎**，支持 PB（1000 TB） 级别的数据；同时也是一款 **全文搜索引擎** 以及 **分析引擎**！

   它是 **基于 Lucene** 实现的全文搜索系统，自身带有*分布式 的 协调管理功能*，可实现 **近实时搜索**！

   它*隐藏了 Lucene 的复杂性*，并提供了简单的 **restful / Java API **

3. Solr

   与 ElasticSearch 相似的全文搜索系统！

   在分布式管理中，它利用了第三方 zookepeer 实现分布式管理！

   ```
    · Solar 选用了 Zookeeper 作为分布式架构下的协调者。
    · Solr 中的每个结点都是对等的，Zookeeper 的使用主要是用来做分片的路由信息，以及各个 replica 之间，overseer 结点的抢主！
    · Solr 中唯一不同的角色就是 overseer，相当于 Solr 集群中的 master 角色，所有的 Collection creation等 admin 操作，都需要经过 overseer 结点。同时，overseer 结点可以根据 AutoScalling 框架的配置，在结点丢失 和 新结点加入时，做一些预设的操作。例如：结点丢失时，为该结点的 replica 自动再 add 一个新 replica，保持可用的 replica 数为固定值
   ```

   支持 Json、XML 等多种数据格式！

   传统搜索应用中 Solr 表现比 ES 好，但实时搜索性能上 ES 更胜一筹！

#### ElasticSearch

##### 介绍

+ ElasticSearch 是一款 高度可扩展的 开源全文搜索引擎，也是一款 分析引擎！

  不单单是搜索，还提供了分析功能！

+ 能快速、近实时地对大数据进行存储、搜索 和分析！

+ 用来支撑 有复杂的 数据搜索需求的企业级应用！

##### 特点

1. 分布式

   即：每个索引使用可配置数量的分片，每个分片上又有多个副本，在任何一个副本分片上 执行读取和搜索操作！

2. 高可用

   ES 分布式的特点，造就了其高可用的特性！ 

   在分布式系统中，某个一节点故障后，不会影响整个系统的使用！

3. 只支持 json

4. 多 API：支持 HTTP Restful API、也支持 java 原生的 API

5. 面向文档：不需要事先定义模式（定义存储结构）

6. 异步写入

   对于同步来说，异步写入性能更高！

7. 近实时：搜索近实时

8. 基于 Lucene

##### 核心概念

###### 近实时

+ 从写入数据到可以被搜索 之间 具有 1s 的延迟！而 Lucene 可以做到实时性！
+ Lucene 的实时性：
  1. 要么牺牲索引的效率：每次搜索之后都需要刷新数据！
  2. 要么牺牲查询效率：每次查询之前都需要刷新数据！

+ ES 选择了折中 的方案：

  每隔 n 秒 自动做一次数据刷新，如此一来，在创建索引之后，最多 n 秒，就能查询到结果 —— 近实时！

  索引建立之后，不会直接写入到磁盘，而是存放在系统缓冲区中，再通过刷新策略，定期将索引同步到磁盘中！

  一般来说，刷新参数都会设置在 1 秒 左右，这就是为什么会有 1s 延迟！

  刷新参数：`index.refresh_interval 设置刷新时间间隔`

###### 集群（Cluster）

+ 集群是 一个或者多个主从结点的集合，用于保存 ElasticSearch 中的全部数据，并提供基于全部结点的集成式的索引和搜索功能！

+ 每个集群都有一个默认的名称：”elasticsearch“！

  结点会通过集群的名称加入指定的集群，因此在同一个应用中，尽量不要使用相同的集群名称，这可能会使得结点加入时产生错误！

###### 结点（Node）

+ 结点 表示 集群服务中的单个服务器，用于存储数据，并参与整个集群的聚合分析和检索！
+ 结点有唯一的名称标识，通常使用 uuid 唯一标识，如果不自定义结点名称，则会在结点启动时，自动分配名称！
+ 通过集群名称可以将 结点加入指定的集群，默认会加入名为”elasticsearch“的集群！

###### 文档（Document）

+ 文档是 ES 中的最小数据单位，它对应于一个实体，相当于 关系型数据库中的一行记录！

+ 实体中的属性 在 文档中称为 **数据字段 （Field）**

+ 文档使用 json 格式表示！

  ```json
  // 例如：一个手机产品 使用 document 表示，其中的属性 称为 Field
  {
      "product_id":"1",
      "product_name":"Xiao Mi",
      "product_desc":"小米手机",
      "catagory_id":"2"
  }
  ```

###### 类型（Type）

- 类型 是索引的细分，也是对不同文档的具体归类，一般根据文档的公共属性进行划分！相当于 关系型数据库中的 表！

  例如：在商品中，可以细分为 手机、电脑、衣服、家具 ... ...

###### 索引（Index）

+ 索引 是 相似文档的 集合。相当于 关系型数据库中的 数据库！

  例如：商品索引。

+ 一个 索引中包含很多 document，一个索引就代表了 一类相似 或者 相同的 document！

+ 每个索引都有一个名称，通过名称可以对索引中的文档进行 crud 操作。

+ 在单个集群中，可以定义任意数量的索引！

###### 分片（shard）

+ 单台机器无法存储大量数据，于是 ES 将一个索引中的数据切分为多个 shard，分布在多台服务器上存储。

  有了 shard 就可以横向扩展，存储更多的数据，让搜索和分析等操作分摊到多台服务器上完成，这样能提高 性能和吞吐量！

+ 每个 shard 都是一个 Lucene index

+ ES 会负责自动对分片的数据进行分配和聚合！

+ 为什么要设置分片？

  ES 需要水平分割或者缩放 分容卷，其次 分片可能分布在多个结点上，这样就可以并处的处理数据，提高性能和吞吐量！

###### 副本（Replica）

+ 作用：

  1. 保证系统高可用

     故障不可避免，为了保证系统高可用，为 shard 创建多个副本，可以为 shard 故障时提供备用服务，保证数据不丢失！

  2. 提高系统吞吐量

     多个 replica 还可以提高 搜索操作的 性能和吞吐量。

+ 建立索引时，默认会创建 5 个 shard，并为每个 shard 分配一个 replica。因此，每个索引默认 10 个分片！

  shard 在创建时指定，并不可修改，而 replica 可随时修改！

+ ES 会自动管理 结点中的分片和副本！
+ 最小的高可用配置是 2 台服务器

![](image\ES 结构.png)

##### 搜索引擎 机制

+ 搜索引擎的三大过程：
  1. 爬取内容
  2. 进行分词（停顿词过滤... ...）
  3. 建立反向索引（倒排索引）

##### 倒排索引

+ 倒排索引 又称为 反向索引！

  根据文章内容中的关键字建立索引！

+ 搜索引擎的原理就是建立倒排索引！

##### ES 分布式原理

+ ES 会在建立索引时，对索引进行分片，默认分成 5 片，并为每个分片分配一个 副本！ES 会将这些分片 分配到 多台服务器中存储，使得 分片与副本之间形成 主从关系，同时多台服务器上的分片形成集群！

  默认情况下，一个索引拥有 10 个分片。

  + 主从分片，主分片写入数据，并同步到 副本分片上，能保证某个服务器宕机后，其他的数据副本能继续提供服务，使得 ES 高可用！
+ 多个分片 使得 ES 可横向扩展，存储更多数据！将分片分配到多个服务器结点上存储，使得 所有的操作 在多台服务器上并行的执行，提高了 ES 的性能 和 吞吐量！

+ ES 集群多个结点，自动选举一个结点作为 master，用于管理集群，例如：维护索引元数据、主从分片的切换等。

  + 如果 master 结点宕机了，那么会重新选举一个结点作为 主节点！

  + 如果 非master 结点宕机了，那么 master 结点会将 宕机结点上的 主分片身份转移到从分片上，当结点重启后，master 会将旧的主分片降级为从分片，并分配给新的主分片，同时同步分片数据，使得集群正常工作！

+ 建立索引时，请求先发送到 master 结点上，master 建立索引之后，会将 集群状态同步到 slave。

  ![](image\ES 建立索引.png)

  注意：只有建立索引 和 类型时需要经过 master 进行同步，数据的写入有一个 简单的 routing 规则，可以 route 到集群中的任意结点，所以数据写入压力是分散到整个集群中的！

##### ES 执行过程

###### ES 写数据

1. 客户端选择一个 集群结点（node） 作为 协调结点（coordinating node），将写请求发送到该结点上！

2. 协调结点 对收到的 文档（document）进行路由，将请求转发到 存储该文档的 分片（shard）上！（实际上是转发到 该分片所在的 node）

3. 主分片处理写请求，并将数据同步到 副本（replica）上！（实际上是转发到该 副本 所在的 node）

4. 当协调结点 发现 分片与副本 都处理完毕之后，便响应客户端！

   ![](image\ES 写数据.png)

###### ES 读数据

+ 当通过 document id 查询时，ES 会对 id 进行哈希，找出该 document 分配的 shard，并查询结果！

1. 客户端选择任意一个 集群结点node，作为 协调结点（coordinate node），将请求发送到该结点上！
2. 协调结点 对 doc id 进行哈希，路由出对应的 node 上，并转发读请求！
3. 收到请求的 node 会使用 随机轮询算法（round-robin），*在目标分片 以及 对应所有副本中* 选择一个，处理读请求，并将 document 返回给 协调结点！（将读请求负载均衡）
4. 协调结点 收到 document 回复后，转发给客户端！

###### ES 搜索数据

1. 客户端将请求发送到一个协调结点！
2. 协调节点 将 搜索请求转发到 所有索引的 分片上（或者副本）
3. query phase（查询阶段）：每个 分片/副本 根据搜索请求，将自己的搜索结果（document id）返回给协调结点！
4. fetch phase（提取阶段）：协调结点对结果进行 **聚合、排序、分页**等操作，最终根据 doc id 获取完整的 document 数据，返回给客户端！

##### ES 底层原理

###### 底层 写

<img src="image\ES 写数据_底层原理.png" style="zoom: 70%;" />

###### 底层 删除/修改

#### 典型应用 ELK

+ ELK 日志分析系统

  + E：ES

  + L：logstash：日志收集系统

  + K：kibana：数据可视化 平台

  logstash 采集业务系统中的日志，存储到 es 中，通过 kibana 展现给运维人员分析！

   ![](image\ELK .png)
