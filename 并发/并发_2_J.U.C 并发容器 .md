#### 【J.U.C_2_并发容器】

##### 并发容器介绍

```java
/*
jdk 提供的 并发容器 都在 J.U.C 包中：
· ConcurrentHashMap		-> 线程安全的 HashMap
· CopyOnWriteArrayList	-> 线程安全的 ArrayList，适合读多写少的场景，性能远远高于 Vector
· ConcurrentSkipListMap ：跳表的实现，使用跳表的结构进行快速查找！
· ConcurrentLinkedQueue	-> 线程安全的 LinkedList，高效的并发队列，是一个非阻塞队列
· BlockingQueue	：是一个 接口，jdk 内部通过链表、数组等方式实现了该接口，表示阻塞队列，非常适合用于数据共享的通道！
*/
```

##### ConcurrentHashMap

```java
/*
HashMap 是线程不安全的，在并发的场景下，如果想使用线程安全的 HashMap，可以使用 HashTable，或者 Collections 提供的静态方法 synchronizedMap 进行包装。
【 HashTable 】
 · HashTable 不允许 key、value 为空，HashMap 允许 key、value 为空！
 · HashTable 通过在方法上使用 对象锁，实现并发访问的线程安全性。HashTable 对所有可访问的方法都加锁，当多个线程涉及到元素访问时，不论是不是同一个 key 都会上锁！简单粗暴，但是任何操作都不能并发执行，性能也极其低！

【 SynchronizedMap 】
 · SynchronizedMap 内部维护了一个 普通的 Map<K,V> 以及 互斥量 Object mutex ！
 · SynchronizedMap 有两个构造方法
 	1、 参数只有一个 Map
 	2、 参数为 Map 、互斥量
 · SynchronizedMap 与 HashTable 一样在内部使用 互斥锁 保证线程安全性！只有一个线程能获取到对象锁！
 	1、 若构造时只传入一个 Map：则对象锁，就是本身的锁
 	2、 若构造时还传入一个 互斥量mutex：则对象锁，就是这个 mutex 对象的锁！
 · 如下图：SynchronizedMap
*/
```

<img src="image\Collections.synchronizedMap.png" style="zoom:50%;" />

```java
/*
实际上，上述两种解决方案都不能完美解决问题，它们只能解决 单个操作时原子性的！
在多个操作复合的情况下 HashMap 依旧是线程不安全的！jdk 5以后 出现了 ConcurrentHashMap 用于替代 HashTable！

=》HashMap 为何线程不安全？
 · HashMap 1.7 时多线程环境下进行扩容，可能会出现 HashMap 死循环
 	原因：元素的插入是头插法，会修改结点之间引用的关系，并发扩容时，很可能出现并发线程同时对其扩容，最后导致结点之间循环引用的问题，当下一个线程访问这个结点时，就会出现死循环！
 · HashMap 1.8 改用 尾插法，不会修改结点间的引用关系，并发扩容时不会出现链表倒置的情况，所以不会产生上述问题。
 · HashMap 并发更新同一个元素时，由于并没有做任何同步，线程之间修改相互覆盖，所以同样是线程不安全的！

=》ConcurrentHashMap 与 HashTable 的区别 ？
1）底层数据结构
	HashMap：
		jdk 1.7 采用 数组+链表
		jdk 1.8 采用 数组+链表/红黑树
	ConcurrentHashMap：
		jdk 1.7 采用 分段数组+链表 
		jdk 1.8 采用 数组+链表/红黑树
	HashTable：
		数组 + 链表
2）线程安全方式
	ConcurrentHashMap：
		jdk 1.7 ：采用分段锁！对整个数组进行分段（Segment），每一把锁只锁一个容器其中一部分数据，多线程访问容器里不同的数据，就不会存在锁竞争，提高并发的访问率！
		jdk 1.8 ：废弃了 分段锁，直接用 Node数组+链表/红黑树 实现，并发控制使用 synchronized 和 CAS 操作（锁住的是桶的首结点），使得线程安全的同时，提升了性能！
	HashTable ：
		一直使用对象锁，线程安全性 由 同步方法控制，当一个线程访问访问同步方法时，其他方法将进入阻塞或者轮询状态，效率低下！
*/
```

###### `ConcurrentHashMap原理 【 jdk 1.7 --- 分段锁segment 】`

![](image\Java7_ConcurrentHashMap .png)

```java
/*
java 7之前的 ConcurrentHashMap 是通过 Segment数组结构 + HashEntry数组 构成。
 · Segment 是继承了 ReentrantLock，所以它是一种可重入锁，Segment 结构和 HashMap 类似，它是一个 数组+链表 的结构。当对 Segment 中的 数据进行操作时，首先需要获取对应的 Setment锁，所以在多线程环境下，对不同 Segment 的数据进行操作，不会发生锁竞争的问题！
 · 默认情况下 concurrencyLevel 为16，表示有 16 个Segment，因此理论上支持 16个线程并发操作！
*/

// 一个 ConcurrentHashMap 包含了一个 Segment 数组
final Segment<K,V>[] segments; 

// 一个 Segment 实例内部守护了一个 HashEntry 数组 ：volatile 修饰！
transient volatile HashEntry<K,V>[] table;

// 每个 HashEntry 可作为 链表的结点，具有 next 引用！
static final class HashEntry<K,V> {
        final int hash;
        final K key;
        volatile V value;
        volatile HashEntry<K,V> next;
        ... ...
}

// Segment 构造方法 ：如下 Segment 具有 填装因子、阈值、表，这与 HashMap 极为类似
Segment(float lf, int threshold, HashEntry<K,V>[] tab) {
    this.loadFactor = lf;//负载因子
    this.threshold = threshold;//阈值
    this.table = tab;//主干数组即HashEntry数组
}

// ConcurrentHashMap 构造方法：分段数量一经创建就不再改变
public ConcurrentHashMap(int initialCapacity,	// 初始化容量	：默认 16
                         float loadFactor, 		// 填装因子		：默认 0.75
                         int concurrencyLevel	// 并发度：Segment 数量	：默认16
	) {
    if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    // MAX_SEGMENTS 为 1<<16 = 65536，也就是最大并发数为 65536
    if (concurrencyLevel > MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    //  2^sshift = segments.size ：sshift 用于定位 segment
    int sshift = 0;
    // segments数组的长度，由 concurrentLevel 计算出
    int ssize = 1;
    while (ssize < concurrencyLevel) {
        ++sshift;
        // 这里不直接使用 concurrentLevel 是因为无法保证 concurrnetLevel 就是 2 的幂次
        ssize <<= 1;
    }
    // segmentShift 用于定位 参与散列运算的位数 ：用于定位 segment 内部的 HashEntry 桶
    // 使用 32 是因为 ConcurrentHashMap 的hash函数中最大的散列值是32位的
    this.segmentShift = 32 - sshift;
    // segmentMask 是散列运算的掩码：ssize-1 即为 全1的二进制序列
    this.segmentMask = ssize - 1;
    
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    
    // 计算每个 Segment 中 HashEntry 桶的大致数量：具体数量必须是 2的幂次 
    int c = initialCapacity / ssize;
    if (c * ssize < initialCapacity)
        ++c;
    int cap = MIN_SEGMENT_TABLE_CAPACITY;
    while (cap < c)
        // cap：桶的数量：必须为 2的幂次
        cap <<= 1;
    
    // 创建 segments 数组并初始化第一个Segment，其余的Segment延迟初始化
    Segment<K,V> s0 =
        new Segment<K,V>(loadFactor, 
                         (int)(cap * loadFactor), // threshold 阈值：cap*loadFactor
                         						// 默认情况下 cap 计算为 1 ，threshold 为 0
                         (HashEntry<K,V>[])new HashEntry[cap]);
    Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
    UNSAFE.putOrderedObject(ss, SBASE, s0); 
    this.segments = ss;
}
/*
上述：
为什么 ssize 必须是 2的幂次 ？	方便通过 按位与 的列散算法 定位 segment
为什么 cap 必须是 2的幂次？		方便通过 按位与 的散列算法 定位 segment 的 hash桶
*/

/*
既然 ConcurrentHashMap 使用分段锁保证并发操作的安全性，那么为了提升并发的性能，就需要使得元素尽量的散列到各个 Segment 中，减少散列冲突，为此 ConcurrentHashMap 除了通过 hashcode 获取元素的哈希码外，还会对 哈希码 再散列！（如下：Wang/Jenkins hash 的变种算法）

类似于这样的散列冲突，在 HashMap 中也有！
*/
private static int hash(int h){
    h += (h << 15) ^ 0xffffcd7d ;
    h ^= (h >>> 10);
    h += (h << 3);
    h ^= (h >>> 6);
    h += (h << 2) + (h << 14);
    return h ^ (h >>> 16);
}

// get 方法
public V get(Object key) {
    Segment<K,V> s; 
    HashEntry<K,V>[] tab;
    // 对 hashcode 再散列：减少散列冲突
    int h = hash(key);
    // 【定位1】
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
    // 先定位Segment，再定位HashEntry
    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&
        (tab = s.table) != null) {
        // 获取对应的桶 ：遍历链表
        for (HashEntry<K,V> e = 
             (HashEntry<K,V>) UNSAFE.getObjectVolatile(
                 	  // 【定位2】
                 tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE
             ); e != null ; e = e.next) {
            K k;
            // HashEntry 数组被 volatile 修饰，保证可见性，不会拿到到过期数据，可直接获取！
            if ((k = e.key) == key || (e.hash == h && key.equals(k)))
                return e.value;
        }
    }
    return null;
}
/*
【定位1】 (h >>> segmentShift) & segmentMask ：获取 h 的高 sshift ：定位 segment
        segmentShift = 32 - sshift
        ssize = 2^sshift
        segmentMask = ssize - 1
        
【定位2】 (tab.lenght -1) & h ：取余（使用 按位与 代替 取余：高效）
		tab.length 为 2的幂次
*/

// put 方法
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    // 尝试获取 segment锁，如果获取失败，则会遍历定位到相应的桶的位置（主要在于在工作线程中缓存）
    HashEntry<K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        HashEntry<K,V>[] tab = table;
        // 桶位置
        int index = (tab.length - 1) & hash;
        HashEntry<K,V> first = entryAt(tab, index);
        for (HashEntry<K,V> e = first;;) {
            if (e != null) {
                // 未到尾结点 ：查询是否存在
                K k;
                if ((k = e.key) == key || (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    // 存在则更新：同时修改次数(modcount)+1 【 fail—fast 】
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                e = e.next;
            }
            else { // 到达尾结点 ：链表中不存在
                if (node != null)
                    // 先将 node 的尾结点 指向 链表的头结点（暗示：头插法）
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);
                int c = count + 1;
                // 判断是否需要扩容，并完成插入（node 置为 链表的的头结点）
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    // 【扩容 再hash】
                    rehash(node);
                else
                    // 头插入：node 置为 链表的头结点
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        unlock();
    }
    return oldValue;
}
/*
=》【 fail-fast策略 】快速失败：
 在上述 put 操作中，如果插入或者对已存在的元素进行修改，则 modCount+1 即修改次数+1。
 modCount 用于并发迭代（foreach、iterator）的时候，检测 集合是否有被其他线程修改过！
	迭代前传入 modCount 作为 原值 expectedModCount
	迭代过程中 当迭代器 使用 next() 与 hasNext() 方法时，会对比 modCount（现值） 与 expectedModCount（原值）判断所在集合是否被其他线程修改，如果两者不一致，则判断为被修改过，抛出异常：ConcurrentModificationException
	
【问题】
	fail-fast 策略并不只是针对其他线程，也是针对自己，自己人为修改完集合后，modCount也会改变，同样会抛出 ConcurrentModificationException 异常！
	
【解决方案】
	1、使用 for 循环！
	2、？ iterator 中实现了remove方法，可在fail-fast策略下，迭代集合时删除元素，修改结果对其他线程都可见！

【put 方法总结】
插入元素时：
	判断是否需要扩容 c > threshold && tab.length < MAXIMUM_CAPACITY
 	 · 如果超出阈值：扩容，并添加 结点
 	 · 否则：在 tab 中定位 桶的位置，并将 node 插入到桶的头结点上！
如何进行扩容？
	在扩容时，首先在对应 segment 中创建一个容量为 2倍【扩容2倍】 的HashEntry数组，然后将原数组中的元素，进行散列后插入到新数组中！为了高效 ConcurrentHashMap 不会对整个容器进行扩容，而是只扩容对应某个 segment ！（每个 segment 都有自己的容量？）
	
=》【为什么要扩容2倍】
 1、保证容量为 2的幂次，便于使用 按位与代替取余 高效的桶寻址（tab.length-1）& hash_value
 2、进行 2 倍扩容，理论上每个桶中，会有一半的元素被 hash 到新一批相应的桶中 ———— 保证元素散列均匀分布！
 	每个被分配出去的元素：新桶位置为：原桶数+原桶索引位置
 	这是因为：散列的时候，使用 按位与 代替取余，当容量变为2倍时，相对于原容量取余，元素的 hash值 就会向高位多取1位！若这一位为 1 则，元素分配到新桶，否则就在原桶，所以理论上会有 一半的元素被分配 出去！
*/
```

###### `ConcurrentHashMap原理 【 jdk 1.8 --- 废弃分段锁 】`

![](image\Java8_ConcurrentHashMap .png)

```java
/*
jdk 1.8 ConcurrentHashMap 取消使用 分段锁，而是采用 CAS 和 synchronized 保证并发安全。
 · ConcurrentHashMap 采用 数组+链表/红黑树 的结构！当 链表长度=8 时，将链表（ 寻址O(n) ） 转换为 红黑树（ 寻址O(logn) ）！
 · synchronized 只锁定当前链表或者红黑树的首结点，这样只要hash不冲突，就不会产生并发访问，效率又显著提升！
*/

/**
 * The array of bins. Lazily initialized upon first insertion.
 * Size is always a power of two. Accessed directly by iterators.
 *
 * ConcurrentHashMap 的数组结构 ，由 volatile 修饰 
 */
transient volatile Node<K,V>[] table;

// 每个 node 元素又可以是一个 链表的结点！
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val;
    volatile Node<K,V> next;
    ... ...
}

/**
 * 最大容量 1 << 30
 */
private static final int MAXIMUM_CAPACITY = 1 << 30;

/**
 * 默认的初始化容量！其值必须是 2 的幂次，至少是 1
 */
private static final int DEFAULT_CAPACITY = 16;
/**
 * 默认填装因子 0.75
 */
private static final float LOAD_FACTOR = 0.75f;

/**
 * 树化的阈值：>=  8 时树化！
 * 插入结点：扩容！
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * 非树化的阈值：<= 6 时非树化！
 * 删除结点：缩容！
 */
static final int UNTREEIFY_THRESHOLD = 6;


// put 操作
final V putVal(K key, V value, boolean onlyIfAbsent) {
    // 不允许 k、v 为 null
    if (key == null || value == null) throw new NullPointerException();
    // 获取 元素hash码，会通过 spread 再散列，使其尽量分布均匀
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh; K fk; V fv;
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
        // 1、如果 hash码 所在桶 为null，记录桶的头结点为 f
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // cas 操作 添加node结点（该桶的头结点） ，失败则重新来过（for循环重新插入）！
            if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))
                break;
        }
        // 2、如果当前的桶不为 null ，并且其首结点 hash值为 -1，说明正在扩容，此时尝试协助扩容！
        else if ((fh = f.hash) == MOVED)
            // 尝试协助扩容！
            tab = helpTransfer(tab, f);
        // 3、检查 头结点是否就是所要 put 的结点 ，onlyIfAbsent：若为 false 则表示允许替换旧值！
        else if (onlyIfAbsent && fh == hash &&
                 ((fk = f.key) == key || fk != null && key.equals(fk)) &&
                 (fv = f.val) != null)
            return fv;
        // 4、都不满足：遍历该链表
        else {
            V oldVal = null;
            // 5、对 头结点加锁 ，使用 synchronized 锁，实现并发的线程安全性！
            synchronized (f) {
                // 6、判断 当前结点是否为 链表结点 
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        binCount = 1;
                        // 遍历链表 
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
                                // 查询到结点，更新后退出
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            // 判断是否到达尾结点
                            if ((e = e.next) == null) {
                                // 是的话：直接添加新结点：尾插入
                                pred.next = new Node<K,V>(hash, key, value);
                                break;
                            }
                        }
                    }
                    // 7、判断当前结点是否为 树结点
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                    else if (f instanceof ReservationNode)
                        throw new IllegalStateException("Recursive update");
                }
            }
            if (binCount != 0) {
                // 8、如果 桶的容量 大于等于(>=) 树化的阈值：树化：转换为 红黑树！
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}

// 获取 hash 码
static final int spread(int h) {
    return (h ^ (h >>> 16)) & HASH_BITS;
}
// cas 操作 
static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v) {
    return U.compareAndSetObject(tab, // Object o  被修改的对象
			((long)i << ASHIFT) + ABASE, // long offset	偏移地址
			c,	// Objext expected	原值
			v); // Objext x	所要设置的值
}

/*
总结：
1、获取元素 hash 值
2、寻址相应的桶，判断桶是否为 null
	true：通过 cas 将结点插入，如果插入失败，则重新来过（for 循环失败重来，重新尝试插入）
break
3、判断 当前桶是否在正在被其他线程扩容！
	true：协助扩容
4、判断 桶的首结点 是否为所要 插入/更新 的结点，并且是否 不覆盖原值 ？
	true：return 原值！
5、以上都不满足：需要遍历桶：首先对桶的头结点加锁 synchronized！
6、判断 桶 是否为 链表结构？
	true：遍历链表 --- 尾插 --- 判断是否需要树化(>=thredhold)
	break
7、判断 桶 是否为 树状结构
	true：遍历树 --- 尾插
	break
8、返回值
*/
```

[HashMap 与 ConcurrentHashMap 中 hash算法详解](https://blog.csdn.net/hskw444273663/article/details/86510813)

+ **为什么放弃分段锁**

  ```
  1. 分段锁 segment 继承于 ReentrantLock 增加了 内存开销，而 JDK 1.8 使用了 cas+Synchronized 锁，优化了内存空间的占用！
  2. 一个 segment 合并了多个 哈希桶，但是，对这些 哈希通而言，产生线程冲突的并不多，这样对于访问同一个 segment 中的不同桶元素而言，需要串行化执行，有损性能！而对于 JDK1.8 而言，采用对 桶首结点进行加锁的方式，实现同一个桶下的线程安全性，锁粒度更低，提高了性能！
  ```

##### CopyOnWriteArrayList ---- 线程安全的 ArrayList

```java
/*
 · CopyOnWriteArrayList 认为读多写少，由于读操作不会修改原有数据，若每次读取都进行加锁，其实是一种资源浪费，所以 读操作 完全不需要加锁，只有 写操作时 才会加锁！
 · CopyOnWriteArrayList 采用读写分离的思想，其内部维护了一个 array 引用，任何写操作都会 加锁并且新建一个 array 副本，并此 array 副本上写入数据，操作完成后再将内部的 array 引用指向新建立的副本！而读取则直接访问 array 引用！
 · 相比于 ReentrantReadWriteLock 读写锁的思想：读共享、写互斥、读写互斥！CopyOnWriteArrayList 不会阻塞任何读取操作，有线程写入时，也可以安全的访问读取操作！只有并发写入时，线程之间才需要同步等待，因此性能更好！
 · CopyOnWriteArrayList 既然 修改操作 会 copy 一份副本，那为什么要加锁？
   这是为了避免并发写入时，copy 出多个副本，由于每次都是改变 array 引用的对象，若不加锁，则线程之间的写操作都会被相互覆盖，相互不可见，这是线程不安全的！
*/

// 类定义
public class CopyOnWriteArrayList<E>
    implements List<E>, RandomAccess, Cloneable, java.io.Serializable {

    /**
     * The lock protecting all mutators.  (We have a mild preference
     * for builtin monitors over ReentrantLock when either will do.)
     */
    final transient Object lock = new Object();

    /** The array, accessed only via getArray/setArray. */
    private transient volatile Object[] array;
	/**
     * Gets the array.  Non-private so as to also be accessible
     * from CopyOnWriteArraySet class.
     */
    final Object[] getArray() {
        return array;
    }
	static <E> E elementAt(Object[] a, int index) {
        return (E) a[index];
    }
    // 可见读取操作没有任何的 加锁操作：因为 array 不会被修改，只会被替换！
    public E get(int index) {
        return elementAt(getArray(), index);
    }
    // 写入
	public E set(int index, E element) {
        // 同步代码块！
        synchronized (lock) {
            Object[] elements = getArray();
            E oldValue = elementAt(elements, index);
            if (oldValue != element) {
                int len = elements.length;
                // 拷贝原数组 
                Object[] newElements = Arrays.copyOf(elements, len);
                newElements[index] = element;
                // array 指向新数组（setter操作）
                setArray(newElements);
            } else {
                setArray(elements);
            }
            return oldValue;
        }
    }
    // 增加元素
    public boolean add(E e) {
        // 同步代码块！
        synchronized (lock) {
            Object[] elements = getArray();
            int len = elements.length;
            // 拷贝原数组！
            Object[] newElements = Arrays.copyOf(elements, len + 1);
            newElements[len] = e;
            // array 引用指向新数组！
            setArray(newElements);
            return true;
        }
    }
}
/*
 【 数组拷贝 】 
 · T[] Arrays.copyOf(T[],int newLength)
 	    public static <T> T[] copyOf(T[] original, int newLength) {
 	    	// 内部也是调用 System.arrayCopy 完成拷贝！
        	return (T[]) copyOf(original, newLength, original.getClass());
    	}
 · System.arrayCopy(Object src,int srcPos,Object dest,int destPos,int length);
        @HotSpotIntrinsicCandidate
        public static native void arraycopy(
            Object src,  int  srcPos,Object dest, int destPos,int length
        );
*/

/*
CopyOnWriteArrayList 缺点：
 · 由于 写操作 需要拷贝数组，就需要消耗内存空间，当数组数据量很大时，可能会导致 Minor GC 或者 Full GC
 · 不能用于实时读取的场景！
   正是由于 写操作的数组拷贝，使得读写可以同时进行，但也意味着 读取到的数据 可能并不是最新的数据！
   它能做到 最终一致性，却无法满足实时性！
   
使用场景：
	适用于读多写少的场景！

设计思想：
	读写分离！
	写操作 加上互斥锁并另外开辟新空间 以解决并发安全性！
	保证 最终一致性！
*/
```

##### ConcurrentSkpListMap

```java
/*
跳表：
 · 跳表 是 链表的升级版本，是一种 快速查找元素 的数据结构。 
 	对于一个单链表，即使链表是有序的，元素的访问都需要 O(N) 的时间复杂度，为了提高效率，可以将有序链表（逻辑上）分为多个段，每一段都提取出段首结点作为该段索引，通过比较索引值，就能跳过不必要的结点，进而快速找到元素大概的位置！这就是跳表！
 	为了维护索引，跳表将 每一段上的索引结点 重新组合成链表！所以，跳表最少有两条链表，一条是索引链，一条是完整的数据链！
 
 · 多级索引跳表
 	当 索引链也变得非常长时，就使用刚才的思想，在索引链上提取出新的索引链，如此往复在新索链提取出索引链，直到 时间复杂度达到 O(logN)！
 	此时，形成的跳表就是多级索引跳表！

 	
 · 最底层的链表维护了跳表内的所有元素，每一层链表都是其下面一层的子集！
 	跳表内的所有链表都是排序的，查找时，可以从顶级链表开始找，一旦发现被查找的元素大于当前链表中的取值，就会转入下一层链表继续查找，即：查找过程中搜索是跳跃式的！

 · 跳表类似于平衡树！
 	相同点：都可以对元素进行快速查找，跳表查找的时间复杂度为：O(logn)
 	不同点：
 		对平衡树的插入和删除往往很可能导致平衡树进行一此全局的调整，而对于跳表的插入和删除只需要对整个跳表的局部进行操作！
 		在高并发场景下，平衡树需要一个全局锁保证整个平衡树的线程安全！对于跳表，只需要访问部分锁即可，所以高并发场景下跳表拥有更好的性能。
*/
```

![](image\跳表.png)

```java
/*
如上：查找 15
 · 对于普通链表，需要查找 6 次
 · 对于跳表，需要查找 3 次
	首先第一级结点查找到 11，第二级链表 11 继续深入，第三级链表 查找到 15
*/

/*
 · 跳表是一个 空间换时间 的算法思想！
 · 在并发数据结构中，jdk 使用跳表实现一个 Map：ConcurrentSkipListMap
 · 使用跳表实现 Map 和使用 哈希算法 实现 Map另一个不同之处在于：
 	哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的，所以，对跳表排序时是一个有序的结果！如果应用中需要使用有序性，则跳表是不二之选！
*/
```

[跳表](https://www.cnblogs.com/alimayun/p/12160786.html)

##### 线程安全的 Queue

```java
/*
java 中提供的线程安全的 Queue 分为 阻塞队列 和非阻塞队列！
 · 阻塞队列典型例子：BlockingQueue 	内部通过 加锁 实现线程安全！
 · 非阻塞队列典型例子：ConcurrentLinkedQueue	内部通过 CAS非阻塞算法 实现线程安全！
*/
```

##### ConcurrentLinkedQueue

```java
/*
 · ConcurrentLinkedQueue 是一个基于 链表 的无界队列，它采用 CAS 操作避免线程阻塞，同时保证了线程的安全性，在高并发场景下，算是性能最好的队列，这都源于其内部复杂的实现！
 · 适用于 对性能要求较高，存在并发读写的场景，但正是由于 ConcurrentLinkedQueue 是无界队列，所以需要注意内存占用或者溢出问题！
*/
// 是一个类：继承自 Queue、AbstractQueue
public class ConcurrentLinkedQueue<E> extends AbstractQueue<E>
        implements Queue<E>, java.io.Serializable { .. ...}
```

##### BlockingQueue

![](image\BlockingQueue 接口方法定义.png)

```java
/*
 · BlockingQueue 是一个阻塞队列，提供了可阻塞的 插入和删除 方法，正是如此，其被广泛使用在 “生产者、消费者” 场景中：当队列满时，生产者被阻塞，直到队列未满；当队列为空时，消费者被阻塞，直到队列非空！
 · BlockingQueue 是一个接口，继承自 Queue，而 Queue又继承自 Colletion
*/
// 是一个接口，仅仅继承自 Queue
public interface BlockingQueue<E> extends Queue<E> { ... ...}

/*
BlockingQueue 有如下实现类：
 · ArrayBlockingQueue
 · LinkedBlockingQueue
 · PriorityBlockingQueue
 · SynchronousQueue
 · DelayQueue（不介绍）
*/
```

###### ArrayBlockingQueue

```java
/*
 · ArrayBlockingQueue 是 BlockingQueue的 有界阻塞队列 实现类！
   内部实现：
   	1、数组（环状）
   	2、ReentrantLock mainLock(全局锁)
   	3、读条件(mainLock.condition) + 写条件(mainLock.condition)
 · ArrayBlockingQueue 容量有限（有界队列），必须在初始化时指定容量大小，并且一经创建，其容量不可被改变！
 · 并发控制采用 可重入锁 实现，无论读取，都需要首先获取锁！
	当队列满时 尝试将元素放入队列的线程 会被阻塞！
  	当队列空时 尝试从队列中获取元素的线程 会被阻塞！
 · 当线程被阻塞后可访问时，ArrayBlockingQueue 对阻塞线程有两种处理方式：
	1、不公平性访问：（默认）
	 · 随机从阻塞线程中获取线程访问，并非按照线程等待的先后顺序！
	 · 有可能出现 长时间阻塞的线程 依然无法访问到 队列 ---- 线程饿死！
	2、公平性访问：
	 · 线程按照阻塞的先后顺序进行访问（即：线程按照等待的时间长短，等待时间长说明先阻塞）！
	 · 通常会降低吞吐量：前面的线程访问的时间过长，后面可在短时间内访问的线程无法执行！
	 · 创建队列时可指定线程的公平性访问：
	   ArrayBlockingQueue<Integer> blockingQueue = new ArrayBlockingQueue<Integer>(10,true);
*/
public class ArrayBlockingQueue<E> extends AbstractQueue<E>
        implements BlockingQueue<E>, java.io.Serializable {
    
    /** The queued items */
    final Object[] items;
    
    // 读操作时：下一步位置（到数组末尾时 自动跳到数组首位：环）
    int takeIndex;

    // 写操作时：下一步位置（到数组末尾时 自动跳到数组首位：环）
    int putIndex;
    
    // Main lock guarding all access ：主锁：锁住并发读写
    final ReentrantLock lock;

    // Condition for waiting takes ：不为空条件锁：阻塞消费者 take 获取元素
    private final Condition notEmpty;

    // Condition for waiting puts ：未满条件锁：阻塞生产者 put 添加元素
    private final Condition notFull;
    
    // 构造器：默认不公平访问机制
    public ArrayBlockingQueue(int capacity) {
        this(capacity, false);
    }
    
    // 构造器：可设定是否公平访问：初始化主锁、两个条件锁
    public ArrayBlockingQueue(int capacity, boolean fair) {
        if (capacity <= 0)
            throw new IllegalArgumentException();
        this.items = new Object[capacity];
        lock = new ReentrantLock(fair);
        notEmpty = lock.newCondition();
        notFull =  lock.newCondition();
    }
    // 生产者 put
    public void put(E e) throws InterruptedException {
        Objects.requireNonNull(e);
        final ReentrantLock lock = this.lock;
        // 加锁
        lock.lockInterruptibly();
        try {
            // 若队列满：count：元素个数
            while (count == items.length)
                // 一直等待
                notFull.await();
            // 队列不满时：元素入队
            enqueue(e);
        } finally {
            // 解锁
            lock.unlock();
        }
    }
    private void enqueue(E e) {
        final Object[] items = this.items;
        items[putIndex] = e;
        // 若操作到数组的末尾，则下一步跳到数组的首位：环
        if (++putIndex == items.length) putIndex = 0;
        count++;
        // 不为空信号！
        notEmpty.signal();
    }

    // 消费者 take
	public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        // 加锁
        lock.lockInterruptibly();
        try {
            // 若队列为空 
            while (count == 0)
                // 一直等待
                notEmpty.await();
            // 若队列不为空：出队
            return dequeue();
        } finally {
            // 解锁
            lock.unlock();
        }
    }
    private E dequeue() {
        final Object[] items = this.items;
        @SuppressWarnings("unchecked")
        E e = (E) items[takeIndex];
        items[takeIndex] = null;
        // 若操作到数组的末尾，则下一步跳到数组首位：环
        if (++takeIndex == items.length) takeIndex = 0;
        count--;
        if (itrs != null)
            itrs.elementDequeued();
        // 元素不满信号！
        notFull.signal();
        return e;
    }
}
```

###### LinkedBlockingQueue

```java
/*
 · LinkedBlockingQueue 是基于 单向链表 实现的阻塞队列，同样满足 FIFO 特性，相比于 ArrayBlockingQueue 有更高的吞吐量！
 · 为防止 LinkedBlockingQueue 容量迅速增加，损耗大量内存，可在创建队列时指定其是否有界：
	创建时指定大小（有界队列）
	创建时未指定，则默认大小为 Integer.Max_VALUE（一定程度上可以认为是无界队列）
 · 内部结构
 	1、单向链表（插入尾结点，读取队首结点）
 	2、读锁(ReentrantLock read) + 读条件(read.condition)
 	3、写锁(ReentrantLock write) + 写条件(write.condition)
 	正是由于 LinkedBlockingQueue 读写锁分离，才会使得吞吐量高于 ArrayBlockingQueue，也正是由于 生产者、消费者 分别操作队列的 last和head（队尾插入，队首获取），所以读写线程互不干扰，线程安全！
*/

public class LinkedBlockingQueue<E> extends AbstractQueue<E>
        implements BlockingQueue<E>, java.io.Serializable {
    	
    	// 单向链表
        static class Node<E> {
        E item;
        /**
         * One of:
         * - the real successor Node
         * - this Node, meaning the successor is head.next
         * - null, meaning there is no successor (this is the last node)
         */
        Node<E> next;
        Node(E x) { item = x; }
    }
    // 队首：head.item === null
    transient Node<E> head;

    // 队尾：last.item === null
    private transient Node<E> last;
    
    //【消费者】 锁住 读
    private final ReentrantLock takeLock = new ReentrantLock();

    //【消费者】 非空：读		空：阻塞
    private final Condition notEmpty = takeLock.newCondition();

    //【生产者】 锁住 写
    private final ReentrantLock putLock = new ReentrantLock();

    //【生产者】 不满：写		满：阻塞
    private final Condition notFull = putLock.newCondition();
    
    // 读写操作与 ArrayBlockQueue 类似，不同在于，这里是读写锁分离！ArrayBlockingQueue 只有一把锁！
}
```

###### PriorityBlockingQueue --- 线程安全的 PriorityQueue

```java
/*
 · PriorityBlockingQueue 线程安全的 PriorityQueye，是一个支持优先级的无界阻塞队列！
 · 内部结构为：
 	1、数组 构建 堆
 	2、ReentrantLock mianLock(全局锁) + mainLock.condition(读条件)
   3、全局 cas 标记：扩容时使用
   4、比较器：调整堆使用（出队、入队、删除 都需要）
 · PriorityBlockingQueue 使用 ReentrantLock 实现并发读写，由于内部使用 数组 实现无界队列，所以需要时再对其进行扩容，避免空间浪费，扩容机制会根据当前容量的大小进行合适的设置！扩容时通过 cas 实现单线程分配新容量、新空间，之后再获取主锁（ReentarntLock），在主锁的控制下，将旧的队列引用指向新空间！
 · PriorityBlockingQueue 不可插入 null（否则抛出异常），并且插入的元素必须是可用 比较器 比较的，否则报错 ClassCastException 异常。由于是无界队列，其 put（插入）方法不会加锁（ 只是逻辑上put操作不需要加锁，然而put 会调用 offer 进行插入，在 offer 方法中会使用 主锁 解决并发插入的安全问题！）；当队列为空时 执行take 的线程会被阻塞！
*/

public class PriorityBlockingQueue<E> extends AbstractQueue<E>
    implements BlockingQueue<E>, java.io.Serializable {
    // 默认初识容量为 11：它是无界队列，队列大小不会受容量控制，当容量不足时会扩容！
    private static final int DEFAULT_INITIAL_CAPACITY = 11;

    // 队列最大长度：Integer.Max_VALUE - 8 （一定程度上算是无界队列）
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
    
    /**
     * 优先权队列 是一个 平衡二叉堆：以数组的形式构建（最大堆、最小堆）
     * queue[n] 的两个子结点 queue[2*n+1] 、queue[2*(n+1)]
     * 对于堆中的任意结点 n 与其后裔结点 d ：n<=d(下标)，若堆不为空，自然排序下，最小元素为 queue[0]
     * 优先权队列 通过 比较器（comparator）进行排序，或者 按照自然排序！
     */
    private transient Object[] queue;

    //priority queue 中 元素的数量
    private transient int size;

    // 元素排序规则；null：默认自然排序：最小堆？
    private transient Comparator<? super E> comparator;

    // Lock used for all public operations：对 public 操作上锁！
    private final ReentrantLock lock;

    // 线程阻塞条件：empty
    private final Condition notEmpty;

    // Spinlock for allocation, acquired via CAS.
    private transient volatile int allocationSpinLock;
    
    // 构造器：指定初始容量，并传入 自定义比较器！
    public PriorityBlockingQueue(int initialCapacity, Comparator<? super E> comparator) {
        if (initialCapacity < 1)
            throw new IllegalArgumentException();
        this.lock = new ReentrantLock();
        this.notEmpty = lock.newCondition();
        this.comparator = comparator;
        this.queue = new Object[initialCapacity];
    }
    
    // never need to block 插入元素：（语义上）队列为无界队列，插入操作不需要加锁！
    public void put(E e) {
        // offer 方法内部会加 互斥锁 解决并发插入的安全问题！
        offer(e);
    }
    // 尝试插入元素
    public boolean offer(E e) {
        // 不可插入 null
        if (e == null)
            throw new NullPointerException();
        final ReentrantLock lock = this.lock;
        // 加锁
        lock.lock();
        int n, cap;
        Object[] array;
        // 插入之前判断是否需要扩容！
        while ((n = size) >= (cap = (array = queue).length))
            // 扩容！
            tryGrow(array, cap);
        try {
            Comparator<? super E> cmp = comparator;
            if (cmp == null)
                // 自然排序：向上调整堆 插入
                siftUpComparable(n, e, array);
            else
                // 自定义的比较器排序：向上调整 插入
                siftUpUsingComparator(n, e, array, cmp);
            size = n + 1;
            // 不为空信号
            notEmpty.signal();
        } finally {
            // 解锁
            lock.unlock();
        }
        return true;
    }
    // 扩容
    private void tryGrow(Object[] array, int oldCap) {
        // must release and then re-acquire main lock：扩容解锁？
        // 扩容时，由于需要分配新空间：耗时，所以需要解除主锁，让其他线程获取主锁，提升性能！
        lock.unlock(); 
        Object[] newArray = null;
        // allocationSpinLock：CAS 锁标记
        // VarHandle 调用 cas 操作：单线程分配新容量！
        if (allocationSpinLock == 0 && ALLOCATIONSPINLOCK.compareAndSet(this, 0, 1)) {
            try {
                // 设置新容量
                int newCap = oldCap + ((oldCap < 64) ?
                                       (oldCap + 2) : // grow faster if small
                                       (oldCap >> 1));
                // possible overflow：判断 新容量 是否溢出
                if (newCap - MAX_ARRAY_SIZE > 0) {
                    int minCap = oldCap + 1;
                    if (minCap < 0 || minCap > MAX_ARRAY_SIZE)
                        throw new OutOfMemoryError();
                    newCap = MAX_ARRAY_SIZE;
                }
                // 按照新容量 新建一个数组：分配新空间
                if (newCap > oldCap && queue == array)
                    newArray = new Object[newCap];
            } finally {
                // CAS 锁标记重置！
                allocationSpinLock = 0;
            }
        }
        // back off if another thread is allocating：判断是否有其他线程正在分配新空间！
        if (newArray == null)
            // newArray 为 null 说明 获取 CAS 锁失败：正在有线程分配新空间！
            // 线程 挂起 置为就绪态！
            Thread.yield();
        // 加锁：获取主锁，将旧队列引用指向新空间！（除 put 外的公有方法都加了 主锁 ！）
        // 此时，下一个线程操作队列时，就是新的队列！
        lock.lock();
        if (newArray != null && queue == array) {
            queue = newArray;
            System.arraycopy(array, 0, newArray, 0, oldCap);
        }
    }
    // 获取元素
    public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        // 加锁（会检查中断状态）
        lock.lockInterruptibly();
        E result;
        try {
            // 判断队列是否为 空
            while ( (result = dequeue()) == null)
                // 等待
                notEmpty.await();
        } finally {
            // 解锁
            lock.unlock();
        }
        return result;
    }
    // 弹出队首
    private E dequeue() {
        int n = size - 1;
        if (n < 0)
            return null;
        else {
            Object[] array = queue;
            // 获取队首
            E result = (E) array[0];
            E x = (E) array[n];
            array[n] = null;
            // 获取比较器
            Comparator<? super E> cmp = comparator;
            if (cmp == null)
                // 自然排序：向下调整堆
                siftDownComparable(0, x, array, n);
            else
                // 自定义比较器排序：向下调整堆
                siftDownUsingComparator(0, x, array, n, cmp);
            size = n;
            // 返回队首结果
            return result;
        }
    }
 // remove删除 contains检查存在 clear清除队列 toArray(拷贝)转换为数组：都会加上 锁！ 
}
```

###### SynchronousQueue

```java
/*
 · SynchronousQueue 是一个无界、非缓存的队列，即：它不存储元素，只要有一个元素插入，则只有等到该元素被消费后才能再插入一个元素。队列内部仅允许容纳一个元素，当一个线程插入一个元素后，就会被阻塞，直到这个元素被另一个线程消费。因此又称它为“同步队列”
 · 队列的设计理念类似于 “单工模式”。对于每个 put/offer 操作生产，必须等待一个 take/poll 操作对其消费，使得队列中并没有一个真正的元素！
 · 方法如下：
 	1、生产：
 		void put(E o)：向队列提交一个元素，并阻塞，直到其他线程 take/poll 此元素！
 		boolean offer(E o)：向队列提交一个元素（不阻塞），如果此时正在有消费者线程正在 take 阻塞等待 或是 碰巧有消费者线程正在尝试 poll，则返回 true，否则返回 false
 	2、消费
 		E take()：获取并删除一个元素，阻塞直到有生产者线程 offer/put
 		E poll()：获取并删除一个元素（不阻塞），如果此时有生产者线程正在 put 阻塞等待 或是 碰巧有生产者线程正在尝试 offer ，则立即返回 元素，否则返回 null
 	3、
 		E peek()：总会返回 null（源码解释：Synchronous 不会返回元素，除非主动等待）
*/
```

+ [SynchronousQueue(同步队列)](https://www.iteye.com/blog/shift-alt-ctrl-1840385)

